#!/usr/bin/env node
/**
 * å»é™¤å›¾ç‰‡æ ‡è®°è„šæœ¬
 * 
 * ä½¿ç”¨ Nano Banana Pro çš„ image-to-image åŠŸèƒ½å»é™¤å›¾ç‰‡ä¸Šçš„ï¼š
 * - å­—æ¯æ ‡è®°ï¼ˆA, B, C, D, E, F, G ç­‰ï¼‰
 * - è‹±æ–‡å•è¯æ ‡è®°ï¼ˆCRITICAL: MIRROR SHA ç­‰ï¼‰
 * 
 * ä½¿ç”¨æ–¹å¼ï¼š
 *   proxychains4 npx tsx src/remove-labels.ts
 */

import { GoogleGenAI } from '@google/genai';
import { setGlobalDispatcher, ProxyAgent } from 'undici';
import fs from 'fs-extra';
import path from 'path';
import chalk from 'chalk';

// é…ç½®å…¨å±€ä»£ç†
const PROXY_URL = process.env.HTTPS_PROXY || process.env.HTTP_PROXY || 'http://127.0.0.1:7890';
setGlobalDispatcher(new ProxyAgent(PROXY_URL));
console.log(chalk.blue(`ğŸ”§ å·²é…ç½®ä»£ç†: ${PROXY_URL}`));

// API é…ç½®
const API_KEY = 'AIzaSyDR1Vwfk4Y_wlGI1tBOlxRd-0OJ6D5-gvs';
const IMAGE_MODEL = 'gemini-3-pro-image-preview';

// é¡¹ç›®æ ¹ç›®å½•
const PROJECT_ROOT = path.resolve(process.cwd(), '../..');
const RESOURCES_DIR = path.join(PROJECT_ROOT, 'resources/images');

// å»é™¤æ ‡è®°çš„æç¤ºè¯
const REMOVE_LABELS_PROMPT = `You are given an isometric pixel art room image that has unwanted text labels and annotations overlaid on it. These labels were accidentally added during image generation and need to be removed.

CRITICAL TASK - REMOVE ALL TEXT MARKERS:

Remove ALL of the following types of text/labels from the image:
1. Single letters (A, B, C, D, E, F, G, etc.) - usually white/yellow bold letters pointing to specific locations
2. English word labels (like "CRITICAL: MIRROR SHA", "CRITICAL: BEAM SHA", "CRITICAL: YIN SHA", "CRITICAL: UNDER-STAIRS SHA", "CRITICAL: SHARP CORNER", etc.)
3. Any arrows or pointer lines connected to these labels
4. Any other text overlays or annotations that are not part of the scene

IMPORTANT PRESERVATION RULES:

1. Keep the EXACT same room layout and structure
2. Keep ALL furniture, decorations, and objects in their original positions
3. Preserve the pixel art style and isometric perspective
4. Maintain the same color palette and lighting
5. Keep any legitimate text that is part of the scene (like book titles on spines, labels on items that belong in the room, Chinese characters on decorations)

TECHNICAL APPROACH:

- Simply paint over the removed labels with the appropriate background colors/textures
- For labels on walls: fill with wall color/texture
- For labels on furniture: restore the furniture surface
- For labels in empty space: remove the text and any connecting arrows/lines
- Ensure smooth integration with no visible editing artifacts

OUTPUT: A clean isometric pixel art room image with NO text labels or annotations overlaid. The image should look exactly like a professional game asset.`;

// é€Ÿç‡é™åˆ¶
const RATE_LIMIT = {
  minIntervalMs: 5000,
};

// é‡è¯•é…ç½®
const RETRY = {
  maxAttempts: 3,
  baseDelayMs: 2000,
  maxDelayMs: 30000,
};

/**
 * ç­‰å¾…æŒ‡å®šæ—¶é—´
 */
function sleep(ms: number): Promise<void> {
  return new Promise(resolve => setTimeout(resolve, ms));
}

/**
 * æŒ‡æ•°é€€é¿é‡è¯•
 */
async function retryWithBackoff<T>(
  operation: () => Promise<T>,
  operationName: string,
  lastRequestTime: { value: number }
): Promise<T> {
  let lastError: Error | null = null;
  
  for (let attempt = 1; attempt <= RETRY.maxAttempts; attempt++) {
    try {
      // é€Ÿç‡é™åˆ¶
      const now = Date.now();
      const elapsed = now - lastRequestTime.value;
      if (elapsed < RATE_LIMIT.minIntervalMs) {
        const waitTime = RATE_LIMIT.minIntervalMs - elapsed;
        console.log(chalk.gray(`  â³ ç­‰å¾… ${(waitTime / 1000).toFixed(1)}s (é€Ÿç‡é™åˆ¶)...`));
        await sleep(waitTime);
      }
      lastRequestTime.value = Date.now();
      
      return await operation();
    } catch (error) {
      lastError = error as Error;
      const errorMessage = (error as Error).message || String(error);
      
      // å¦‚æœæ˜¯é€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´
      if (errorMessage.includes('429') || errorMessage.includes('rate') || errorMessage.includes('quota')) {
        const delay = Math.min(RETRY.maxDelayMs, RETRY.baseDelayMs * Math.pow(2, attempt));
        console.log(chalk.yellow(`  âš ï¸ é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… ${delay / 1000}s åé‡è¯• (${attempt}/${RETRY.maxAttempts})...`));
        await sleep(delay);
        continue;
      }
      
      // å…¶ä»–é”™è¯¯
      if (attempt < RETRY.maxAttempts) {
        const delay = Math.min(RETRY.maxDelayMs, RETRY.baseDelayMs * Math.pow(2, attempt));
        console.log(chalk.yellow(`  âš ï¸ ${operationName} å¤±è´¥: ${errorMessage}`));
        console.log(chalk.yellow(`  ğŸ”„ ${delay / 1000}s åé‡è¯• (${attempt}/${RETRY.maxAttempts})...`));
        await sleep(delay);
      }
    }
  }
  
  throw new Error(`${operationName} å¤±è´¥ï¼Œå·²é‡è¯• ${RETRY.maxAttempts} æ¬¡: ${lastError?.message}`);
}

/**
 * å¤„ç†å•å¼ å›¾ç‰‡
 */
async function processImage(
  client: GoogleGenAI,
  inputPath: string,
  outputPath: string,
  lastRequestTime: { value: number }
): Promise<boolean> {
  const fileName = path.basename(inputPath);
  console.log(chalk.cyan(`\nğŸ¨ å¤„ç†: ${fileName}`));
  
  try {
    // è¯»å–å›¾ç‰‡
    const imageBuffer = await fs.readFile(inputPath);
    console.log(chalk.gray(`  ğŸ“¦ å›¾ç‰‡å¤§å°: ${(imageBuffer.length / 1024).toFixed(1)} KB`));
    
    // è°ƒç”¨ API
    const response = await retryWithBackoff(async () => {
      const contents = [
        { text: REMOVE_LABELS_PROMPT },
        {
          inlineData: {
            mimeType: 'image/png',
            data: imageBuffer.toString('base64')
          }
        }
      ];
      
      return await client.models.generateContent({
        model: IMAGE_MODEL,
        contents: contents,
        config: {
          responseModalities: ['TEXT', 'IMAGE']
        }
      });
    }, 'å›¾ç‰‡å¤„ç†', lastRequestTime);
    
    // è§£æå“åº”
    const parts = response.candidates?.[0]?.content?.parts || [];
    let imageData: Buffer | undefined;
    
    for (const part of parts) {
      if (part.inlineData?.data) {
        imageData = Buffer.from(part.inlineData.data, 'base64');
      }
    }
    
    if (!imageData) {
      console.log(chalk.red(`  âŒ æœªè¿”å›å›¾ç‰‡æ•°æ®`));
      return false;
    }
    
    // ä¿å­˜å›¾ç‰‡
    await fs.writeFile(outputPath, imageData);
    console.log(chalk.green(`  âœ… å·²ä¿å­˜: ${outputPath}`));
    console.log(chalk.gray(`  ğŸ“¦ æ–°å›¾ç‰‡å¤§å°: ${(imageData.length / 1024).toFixed(1)} KB`));
    
    return true;
  } catch (error) {
    console.log(chalk.red(`  âŒ å¤„ç†å¤±è´¥: ${(error as Error).message}`));
    return false;
  }
}

/**
 * éœ€è¦å¤„ç†çš„å›¾ç‰‡æ¸…å•ï¼ˆç”¨æˆ·æŒ‡å®šï¼‰
 */
const IMAGES_TO_PROCESS = [
  // level4: room-cold, room-warm
  { level: 4, file: 'room-cold.png' },
  { level: 4, file: 'room-warm.png' },
  // level6: room-cold, room-warm
  { level: 6, file: 'room-cold.png' },
  { level: 6, file: 'room-warm.png' },
  // level12: room-cold, room-warm
  { level: 12, file: 'room-cold.png' },
  { level: 12, file: 'room-warm.png' },
  // level15: room-cold
  { level: 15, file: 'room-cold.png' },
  // level17: room-cold
  { level: 17, file: 'room-cold.png' },
  // level18: room-cold, room-warm
  { level: 18, file: 'room-cold.png' },
  { level: 18, file: 'room-warm.png' },
  // level19: room-cold, room-warm
  { level: 19, file: 'room-cold.png' },
  { level: 19, file: 'room-warm.png' },
  // level20: room-cold
  { level: 20, file: 'room-cold.png' },
];

/**
 * è·å–éœ€è¦å¤„ç†çš„å›¾ç‰‡åˆ—è¡¨
 */
async function scanImages(): Promise<string[]> {
  const images: string[] = [];
  
  for (const item of IMAGES_TO_PROCESS) {
    const filePath = path.join(RESOURCES_DIR, `level${item.level}`, item.file);
    if (await fs.pathExists(filePath)) {
      images.push(filePath);
    } else {
      console.log(chalk.yellow(`  âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: ${filePath}`));
    }
  }
  
  return images;
}

/**
 * ä¸»å‡½æ•°
 */
async function main() {
  console.log(chalk.bold.blue('\nğŸ–¼ï¸  å›¾ç‰‡æ ‡è®°å»é™¤å·¥å…·\n'));
  console.log(chalk.gray('ä½¿ç”¨ Nano Banana Pro (gemini-3-pro-image-preview) å»é™¤å›¾ç‰‡ä¸Šçš„æ ‡è®°\n'));
  
  // åˆå§‹åŒ–å®¢æˆ·ç«¯
  const client = new GoogleGenAI({ apiKey: API_KEY });
  
  // æ‰«æå›¾ç‰‡
  console.log(chalk.bold('ğŸ“‚ æ‰«æå›¾ç‰‡...'));
  const images = await scanImages();
  console.log(chalk.gray(`   æ‰¾åˆ° ${images.length} å¼ å›¾ç‰‡\n`));
  
  if (images.length === 0) {
    console.log(chalk.yellow('æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„å›¾ç‰‡'));
    return;
  }
  
  // æ˜¾ç¤ºå›¾ç‰‡åˆ—è¡¨
  console.log(chalk.bold('ğŸ“‹ å¾…å¤„ç†å›¾ç‰‡åˆ—è¡¨:'));
  images.forEach((img, idx) => {
    const relPath = path.relative(RESOURCES_DIR, img);
    console.log(chalk.gray(`   ${idx + 1}. ${relPath}`));
  });
  
  console.log(chalk.bold('\nğŸš€ å¼€å§‹å¤„ç†...\n'));
  
  // å¤„ç†å›¾ç‰‡
  const lastRequestTime = { value: 0 };
  let successCount = 0;
  let failCount = 0;
  
  for (const imagePath of images) {
    const success = await processImage(client, imagePath, imagePath, lastRequestTime);
    if (success) {
      successCount++;
    } else {
      failCount++;
    }
    
    // æ¯å¼ å›¾ç‰‡ä¹‹é—´ç­‰å¾…ä¸€ä¸‹
    await sleep(2000);
  }
  
  // æ˜¾ç¤ºç»“æœ
  console.log(chalk.bold('\nğŸ“Š å¤„ç†ç»“æœ:'));
  console.log(chalk.green(`   âœ… æˆåŠŸ: ${successCount}`));
  console.log(chalk.red(`   âŒ å¤±è´¥: ${failCount}`));
  console.log(chalk.gray(`   ğŸ“ æ€»è®¡: ${images.length}\n`));
  
  if (failCount > 0) {
    console.log(chalk.yellow('âš ï¸ éƒ¨åˆ†å›¾ç‰‡å¤„ç†å¤±è´¥ï¼Œå¯ä»¥é‡æ–°è¿è¡Œè„šæœ¬é‡è¯•'));
  }
  
  console.log(chalk.bold.green('âœ¨ å¤„ç†å®Œæˆï¼\n'));
}

// è¿è¡Œ
main().catch(error => {
  console.error(chalk.red('\nâŒ è„šæœ¬æ‰§è¡Œå¤±è´¥:'), error);
  process.exit(1);
});
